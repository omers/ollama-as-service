---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      containers:
        - name: ollama
          image: ollama/ollama:latest
          command:
            - /bin/bash
            - -c
            - |
              echo "Starting Ollama"
              ollama serve &
              sleep 15
              echo "Running Ollama"
              ollama run llama3.2 & wait
          ports:
            - containerPort: 11434
              name: http
          resources:
            requests:
              memory: "4Gi"
              cpu: "1"
            limits:
              memory: "12Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
spec:
  type: ClusterIP
  selector:
    app: ollama
  ports:
    - port: 8087
      targetPort: 11434
      protocol: TCP
      name: http


---
apiVersion: apps/v1
kind: Deployment
metadata:
 name: open-webui-deployment
 labels:
   app: open-webui
spec:
 replicas: 1
 selector:
   matchLabels:
     app: open-webui
 template:
   metadata:
     labels:
       app: open-webui
   spec:
     containers:
       - name: open-webui
         image: ghcr.io/open-webui/open-webui:main
         ports:
           - containerPort: 8080
             protocol: TCP
         env:
           - name: OLLAMA_BASE_URL
             value: "http://ollama-service:8087"
           - name: OLLAMA_API_BASE_URL
             value: "http://ollama-service:8087/api"

---
apiVersion: v1
kind: Service
metadata:
  name: open-webui-service
spec:
  type: ClusterIP
  selector:
    app: open-webui
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http